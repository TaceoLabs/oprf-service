#import "preamble.typst": *
#import "@preview/frame-it:2.0.0": *
#import "@preview/dashy-todo:0.1.3": todo

#let inst_taceo = institute("TACEO", email: "papers@taceo.io");

#let authors = (
  author("Daniel Kales", insts: inst_taceo),
  author("Roman Walch", insts: inst_taceo),
)

#let title = "A Nullifier Protocol based on a Verifiable, Threshold OPRF"
#let abstract = "In this paper we describe a service capable of creating publicly verifiable nullifiers using a threshold version of a verifiable oblivious pseudo random function (OPRF). Our construction is based on the TwoHashDH OPRF, discrete logarithm equality proofs, Shamir secret sharing and zk-SNARKs."
#let keywords = ("OPRF", "VOPRF", "threshold", "ZKP")

#show: report.with(
  title: title,
  authors: authors,
  abstract: abstract,
  keywords: keywords,
)

// Custom commands

#let sk = $serif("sk")$;
#let pk = $italic("pk")$;
#let com = $serif("com")$;
#let nonce = $italic("nonce")$;
#let uid = $italic("id")_italic("u")$;
#let rpid = $italic("id")_italic("rp")$;
#let action = $italic("action")$

// frames, needs to be after the report import, as something breaks that otherwise

#let (remark, implementation) = frames(
  remark: ("Remark",),
  implementation: ("Implementation Note",),
)
#show: frame-style(styles.hint)

#outline()


= Introduction

Semaphore @semaphorev4 is a zero-knowledge protocol that allows users to cast a message (e.g., a vote) as a provable member of a predetermined group, without revealing their actual identity. Internally it also produces a nullifier, which can be stored and is used to prevent users from casting a message twice (e.g., prevent double voting). The basic workflow of Semaphore is as follows: Users first create an identity (a private/public keypair) and add a so-called identity commitment to a public Merkle tree. These Merkle trees are usually managed on-chain and define the group members, as all identities committed to in the leaves of the Merkle tree are part of a group. Finally, to send a message, a user creates a zero-knowledge proof that shows: (i) they hold the secret key for a given identity, (ii) the given identity is committed to in the Merkle tree corresponding to a given public root hash and (iii) the produced nullifier is computed correctly for the given message as $H(sk, "scope")$. Since the nullifier is enforced to be computed correctly in the ZK proof, it can be used to check that a given secret key is only used once for a given scope.

The Semaphore protocol is already in version 4 and audited implementations of the circuits and client SDK exist.#footnote[See https://docs.semaphore.pse.dev for more details.] However, for some especially long-running use-cases there exists some drawbacks as well: First, the standard Semaphore protocol equates a group member with a single identity. This lack of account abstraction makes multi-device support as well as recovery of group membership when losing a secret key difficult. Second, since the secret key of the identity is directly hashed as part of the nullifier, leakage of this secret key allows all entities to create nullifier hashes for any scopes. This obviously allows account takeover, but additionally also allows historical analysis of this accounts behavior, linking together nullifiers from different scopes.

In this document we propose a nullifier protocol that improves upon these aspects. First, as a minor change, the Merkle tree holding the accounts now has an additional layer that allows accounts to add a small number of identities in a single leaf, allowing for any of those identities to be used to create the nullifier. This introduces some problems, since now we can no longer use the secret key as part of the nullifier, since an account can now have multiple identities. To address this, we remove the secret key as part of the nullifier altogether, and use the index of the account in the Merkle tree instead. Just doing this na√Øvely breaks some privacy aspects of the nullifier, since now anyone could try to brute force the nullifier hash for some given index, and therefore trace actions of a specific account.

To add another secret back into the nullifier calculation, we employ an Oblivious Pseudorandom Function, where the client inputs the index into the OPRF protocol and the OPRF server holding a key $k$ returns $F_k (i)$, without learning $i$. In this setup, there is now a secret $k$ that is part of the nullifier calculation, however, it is known to the OPRF server, which could still perform the above attack. To address this, the OPRF key is secret-shared between a set of nodes, and a threshold OPRF protocol is executed instead. This protects against a malicious server, but we also need to enforce that clients cannot query arbitrary OPRF inputs, as this would allow them to calculate nullifiers of other accounts. To this end, the clients also proof in zero-knowledge that they know a secret key for a given identity in the leaf that is queried in the OPRF.

Finally, an important part of the original Semaphore protocol is the zero-knowledge proof attesting the correct calculation of the nullifier. We still require this property, but have to extend it with the correct calculation of the OPRF. Therefore, a verifiable variant of the OPRF is used, which allows the OPRF servers to prove the correct calculation of the OPRF against a known public key. This proof must then be verified in the zero-knowledge proof attesting the correct calculation of the nullifier.


= Background

== Notation

In the rest of the manuscript, if not described otherwise, we refer to the prime describing the scalarfield of the BN254 curve (which is also the basefield of the BabyJubJub curve) as $p$ and refer to the prime describing the scalarfield of the BabyJubJub curve as $q$. Furthermore, we denote field elements $in bb(F)$ with small letters, whereas elliptic curve points are denoted by capital letters. To denote a secret sharing of a value $x$ or $X$ we use a bracket notation $[x]$ and $[X]$.

== BabyJubJub <sec:babyjubjub>

BabyJubJub is an elliptic curve designed for efficient operations inside zk-SNARKs that operate over the BN254 scalar field. The main efficiency aspects stem from the fact that the BN254 scalar field is the base field of BabyJubJub and therefore we can directly operate on the $(x,y)$ coordinate representation in the proof system without having to use foreign field arithmetic, which is notoriously expensive. BabyJubJub is defined in EIP-2494 @eip2494, and it should be noted that there are a few conflicting definitions floating around that use slightly different, isomorphic curves instead.

#implementation[On the `ark-ed-on-bn254` crate][At the time of writing, the `ark-ed-on-bn254` crate is one of these conflicting implementations, as its definition of the twisted Edwards curve is actually using the "Reduced Twisted Edwards" form from @eip2494 and is therefore incompatible, although cheap mapping functions do exist. That is why we created a new crate `ark-babyjubjub` that follows the definitions below.]

The definitions below follow the EIP-2494 proposal and are compatible with existing implementations in Circom. We repeat the definitions of the BabyJubJub curve below.

=== Definition of BabyJubJub
Let
$ p = 21888242871839275222246405745257275088548364400416034343698204186575808495617 $ and $bb(F)_p$ be the finite field with $p$ elements. $p$ is the order of the scalar field of the elliptic curve BN254, a common pairing curve used in zk-SNARKs.

==== Twisted Edwards Form

Let $E$ be the twisted Edwards elliptic curve defined over $bb(F)_p$ described by the equation $ 168700x^2 + y^2 = 1 + 168696 x^2 y^2. $ $E$ is called BabyJubJub and has order $ n = 21888242871839275222246405745257275088614511777268538073601725287587578984328, $ which factors into $n = h dot q$, where the cofactor $h = 8$ and the prime $ q = 2736030358979909402780800718157159386076813972158567259200215660948447373041. $

The generator point $G_E$ of the elliptic curve is the point of order $n$ with $ G_E = (995203441582195749578291179787384436505546430278305826713579947235728471134,\ 5472060717959818805561601436314318772137091100104008585924551046643952123905). $
The base point $G$ is chosen to be $G = 8G_E$ and has order $q$. Let $ G = (5299619240641551281634865583518297030282874472190772894086521144482721001553, \
  16950150798460657717958625567821834550301663161624707787222815936182638968203). $
In the following, we usually work with points in the prime-order subgroup generated by $G$.

==== Montgomery Form

Let $E_M$ be the Montgomery elliptic curve defined over $bb(F)_p$ described by the equation $ v^2 = u^3 + 168698u^2 + u. $



$E_M$ is birationally equivalent to $E$, and the following mappings are used to convert points from one curve to the other.

$ E_M mapsto E: (u,v) -> (x,y) = (u/v, (u-1)/(u+1)) $
$ E mapsto E_M: (x,y) -> (u,v) = ((1+y)/(1-y), (1+y)/((1-y)x)) $


== EdDSA on BabyJubJub

One of the main use-cases of BabyJubJub is to build a digital signature scheme from it and verify the resulting signatures in a Groth16 proof. EdDSA is somewhat standardized in RFC 8032 @rfc8032, however, concrete details are only given for the specific curves Curve25519 and Curve448. Furthermore, the default internal hash functions, such as SHA-512, are not zk-SNARK friendly. We instantiate an EdDSA variant using the BabyJubJub elliptic curve and the Poseidon2 @GrassiKS23 hash function for the Fiat-Shamir transform in @alg:eddsa. We also refer to @ChalkiasGN20 for a rigorous treatment of EdDSA variants and follow their recommendations to achieve a strongly unforgeable variant. The variant below is also "cofactored", meaning it is amenable to batch verification.

#show: style-algorithm
#algorithm-figure(
  "BabyJubJub/Poseidon EdDSA signature",
  stroke: black,
  {
    import algorithmic: *
    Function(
      "KeyGen",
      $$,
      {
        LineComment(Assign[$k$][${0,1}^256$], [Sample random $k$])
        LineComment(Assign[$(h_0,h_1,...,h_511)$][$serif("Blake3")(k)$], [Expand secret using hash function])
        LineComment(
          Assign[$sk$][$2^251 + h_250 dot 2^250 + dots + h_3 dot 2^3$],
          [Compute secret scalar, with specific bits chosen],
        )
        LineComment(Assign[$pk$][$sk dot G$], [Compute the public key])
        Return[$sk, (h_256,...,h_511), pk$]
      },
    )
    LineBreak
    Function(
      "Sign",
      $M, sk, (h_256,...,h_511)$,
      {
        LineComment(Assign[$r$][$serif("Blake3")(h_256||...||h_511||M)$], [Generate a pseudorandom nonce])
        LineComment(Assign[$R$][$r dot G$], [Interpret $r$ as a scalar and obtain a curve point ])
        LineComment(Assign[$e$][$serif("Poseidon2")(R||pk||M)$], [Compute the challenge $e$])
        Assign[$s$][$r + e dot sk mod q$]
        Return[$R,s$]
      },
    )
    LineBreak
    Function(
      "Verify",
      $M, pk, sigma = (R,s)$,
      {
        LineComment(Line([Reject if $S in.not {0,..,q-1}$]), [Check for non-canonical $s$])
        Line([Reject if $A$ is one of the small-order points on $E$.])
        Line([Reject if $A$ or $R$ are non-canonical.])
        LineComment(Assign[$e$][$serif("Poseidon2")(R||pk||M)$], [Compute the challenge $e$])
        Line([Accept if $8(s dot B - R - e dot pk) = 0$])
      },
    )
  },
)  <alg:eddsa>


== TwoHashDH OPRF

In this paper we aim to build a distributed and verifiable OPRF service. Our main construction is derived from the TwoHashDH OPRF which was introduced in @JareckiL10. We give its basic construction in @fig:twohashdh, where $H(x)$ hashes the input field element onto an elliptic curve (instantiated with BabyJubJub in our case) and $H'(dot)$ is a cryptographic hash function (Poseidon2 in our case).

#figure(
  rect(table(
    columns: (2fr, 1fr, 2fr),
    stroke: none,
    table.header([Client($x$)], [], [Server($k$)]),
    table.hline(stroke: 0.05em),
    [$beta arrowrl bb(Z)_q^*$], [], [],
    [$A <- beta dot H(x)$], math.attach($arrow.r$, t: $A$), [$B <- k dot A$],
    [], math.attach($arrow.l$, t: $B$), [],
    [Output $H'(x, (beta^(-1) dot B))$],
  )),
  caption: [The TwoHashDH OPRF construction from @JareckiL10.],
  kind: "scheme",
  supplement: [Scheme],
)
<fig:twohashdh>

A long line of work building on the TwoHashDH OPRF exists, adding various properties such as verifiability @JareckiKK14, threshold variants @JareckiKKX17, amongst others. We refer the reader to a recent OPRF systematization of knowledge @CasacubertaHL22 for more details and references.

== Mapping inputs to Curve Points

The above OPRF in @fig:twohashdh requires a function $H: bb(F)_p mapsto E$ to encode the OPRF input into a curve point. We follow the recommendations in RFC 9380 @rfc9380 "Hashing to Elliptic Curves". For the BabyJubJub curve we are using, this internally boils down to hashing the input into a field element, calling the Elligator2 @BernsteinHKL13 mapping to get a point on the Montgomery curve $E_M$, mapping this point onto $E$ via the birational map, and finally clearing the cofactor. We give an overview in @alg:hash2curve and refer to more details in @rfc9380. The `encode_to_curve` function gives a point with unknown discrete logarithm on the curve, however, the returned point is not uniform, as the Elligator2 map cannot hit about $50%$ of curve points. To get a truly uniform random point, the `hash_to_curve` function can be used instead, which internally maps to two points and adds them. However, for most use cases the `encode_to_curve` functions should be enough.

#show: style-algorithm
#algorithm-figure(
  "Hashing to elliptic curves",
  stroke: black,
  {
    import algorithmic: *
    Function(
      "encode_to_curve",
      $x$,
      {
        LineComment(Assign[$u$][$H(x)$], [Hash the input $x$ into a field element])
        LineComment(
          Assign[$R$][$serif("elligator2_map_to_curve")(u)$],
          [Use the Elligator2 map to get a point $R$ on $E_M$],
        )
        LineComment(Assign[$Q$][$serif("birational_map")(R)$], [Use the birational map to get a point on $E$])
        LineComment(Assign[$P$][$h Q$], [Clear the cofactor by multiplication.])
        Return[$P$]
      },
    )
    LineBreak
    Function(
      "hash_to_curve",
      $x$,
      {
        LineComment(Assign[$u_1,u_2$][$H(x)$], [Hash the input $x$ into two field elements])
        LineComment(
          Assign[$R_1$][$serif("elligator2_map_to_curve")(u_1)$],
          [Use the Elligator2 map to get a point $R_1$ on $E_M$],
        )
        LineComment(
          Assign[$R_2$][$serif("elligator2_map_to_curve")(u_2)$],
          [Use the Elligator2 map to get a point $R_2$ on $E_M$],
        )
        Assign[$R$][$R_1 + R_2$]
        LineComment(Assign[$Q$][$serif("birational_map")(R)$], [Use the birational map to get a point on $E$])
        LineComment(Assign[$P$][$h Q$], [Clear the cofactor by multiplication.])
        Return[$P$]
      },
    )
  },
)  <alg:hash2curve>

== Discrete Logarithm Equality (DLogEq) Proof


Adding verifiability to @fig:twohashdh can be done by adding a discrete logarithm equality proof @ChaumP92. The OPRF server is required to publish a public key $K = k dot G$, where $G$ is a known point (in practice, this can just be the base point). The server then proves to the client that it has used the same key $k$ in the OPRF evaluation @JareckiKK14. In the following we describe how one can prove that two group elements $A$ and $B$ share the same discrete logarithm $k$ for their respective bases $G$ and $H$. In other words, given $A, B, G, H in bb(G)$, we show that $A=k dot G$ and $B = k dot H$ for the same $k in bb(F)_q$. The following algorithm specifies $G$ as an arbitrary group element, in practice $G$ can simply be chosen as the generator of $bb(G)$.

#show: style-algorithm
#algorithm-figure(
  "Discrete Logarithm Equality (DLogEq) Proof",
  stroke: black,
  {
    import algorithmic: *
    Function(
      "Prove",
      $k, G, H$,
      {
        LineComment(Assign[$r$][$bb(F)_q$], [Sample random $r$])
        Assign[$R_1$][$r dot G$]
        Assign[$R_2$][$r dot H$]
        Assign[$e$][$H(k dot G,G, k dot H,H,R_1, R_2) in bb(F)_q$]
        Assign[$s$][$r + e dot k$]
        Return[$(e,s)$]
      },
    )
    LineBreak
    Function(
      "Verify",
      $A, B, G, H, (e, s)$,
      {
        LineComment(Line([Reject if $s in.not {0,..,q-1}$]), [Check for non-canonical $s$])
        If("not " + `validPoints` + $(A, B, G, H)$, { Return[$bot$] })
        If("not " + `nonZeroPoints` + $(A,B,G,H)$, { Return[$bot$] })
        Assign[$R_1$][$s dot G -e dot A$]
        Assign[$R_2$][$s dot H -e dot B$]
        If("not " + `nonZeroPoints` + $(R_1, R_2)$, { Return[$bot$] })
        Assign[$e'$][$H(A,G, B,H,R_1, R_2) in bb(F)_q$]
        Return[$e=e'$]
      },
    )
  },
)  <alg:prover>

= A Threshold OPRF Protocol with Verifiability independent of the Number of Servers

In this section we describe the full protocol between the client and multiple OPRF servers. We start by describing threshold variants of the OPRF construction and the discrete logarithm equality proof, before we give our full protocol with the accompanying zero-knowledge proofs.

== Threshold OPRF

Translating @fig:twohashdh from a single-server OPRF to a threshold OPRF is trivial. Since the server (in the single server setting) only performs one group operation $B <- k dot A$ on a blinded $A$, $k$ can just be secret-shared (e.g., using additive or Shamir @Shamir79 secret-sharing) and the client reconstructs the response point $B$ from the shares. The protocol is given in @fig:twohashdh_mpc. Thereby, the properties of the used secret-sharing protocol (e.g., honest/dishonest majority, threshold, etc.) are inherited. For a discussion on threshold OPRFs in general we refer to @CasacubertaHL22.

#figure(
  rect(table(
    columns: (2fr, 1fr, 2fr),
    stroke: none,
    table.header([Client($x$)], [], [$n$ Server($[k]$)]),
    table.hline(stroke: 0.05em),
    [$beta arrowrl bb(Z)_q^*$], [], [],
    [$A <- beta dot H(x)$], math.attach($arrow.r$, t: $A$), [$[B] <- [k] dot A$],
    [], math.attach($arrow.l$, t: $[B]$), [],
    [$B <-mono("Reconstruct")([B])$], [], [],
    [Output $H'(x, (beta^(-1) dot B))$],
  )),
  caption: [The distributed TwoHashDH OPRF construction derived from @fig:twohashdh.],
  kind: "scheme",
  supplement: [Scheme],
)
<fig:twohashdh_mpc>

== Standard Ways to achieve Verifiability

A verifiable OPRF protocol allows the OPRF client to ensure that the OPRF servers have correctly evaluated the OPRF function on the client's input. In the single-server setting, this can be achieved by having the server publish a public key $K = k dot G$ and proving that the same $k$ was used in the OPRF evaluation via a discrete logarithm equality (DLogEq) proof @ChaumP92, as described in @alg:prover. In the multi-server setting, we can achieve verifiability by having each server publish a public key share $K_i = k_i dot D$ and then proving that the same $k_i$ was used in the OPRF evaluation using one DLogEq proof per party. We show this below in @fig:twohashdh_mpc_dlog.

#figure(
  rect(table(
    columns: (2fr, 1fr, 2fr),
    stroke: none,
    table.header([Client($x$)], [], [$n$ Servers($[k]$)]),
    table.hline(stroke: 0.05em),
    [$beta arrowrl bb(Z)_q^*$], [], [],
    [$A <- beta dot H(x)$], math.attach($arrow.r$, t: $A$), [$B_i <- k_i dot A$],
    [], [], [$pi_i <- mono("DLogEq.Proof")(k_i, G, A)$],
    [], math.attach($arrow.l$, t: $B_i, pi_i$), [],
    [$B <-mono("Reconstruct")([B])$], [], [],
    [$forall i: mono("DLogEq.Verify")(K_i, B_i, G, A, pi_i)$], [], [],
    [Output $H'(x, (beta^(-1) dot B))$],
  )),
  caption: [The distributed TwoHashDH OPRF construction derived from @fig:twohashdh_mpc, with added verifiability.],
  kind: "scheme",
  supplement: [Scheme],
)
<fig:twohashdh_mpc_dlog>

This keeps the single request-response flow of the OPRF protocol, but adds a drawback: The client needs to verify a number of DLogEq proofs that scale with the set of servers participating in the OPRF protocol (or more concretely, the threshold used in the secret sharing scheme). Looking ahead, we want to recursively proof correct execution of the OPRF protocol in a zkSNARK, and having this part be dependent on the threshold has two problems: (i) the ZK circuit is different for different configurations of threshold and number of parties, which means zkSNARKs with a circuit-dependent setup phase have to perform that setup phase for each threshold that will be used and (ii), the cost of the zkSNARK prover scales with the number of constraints in the system, and going to a large set of parties ($30+$) dominates other parts in the ZK circuit and makes it prohibitively expensive.

== Distributed Discrete Logarithm Equality Proof

To address the issues in the last section, we present a way to distribute the DLogEQ proof itself, essentially executing @alg:prover in a multiparty computation setting. This setting is very similar to the setting of Threshold EdDSA signatures and we use techniques from this line of work in the following.

=== Additively Shared Discrete Logarithm Equality Proof

In this section we describe how to distribute @alg:prover to multiple provers, where each prover has an additive secret-share of the value $k$. To reduce communication complexity, we introduce an accumulator party which reconstructs public values and computes challenges. Thus, each prover only has to communicate with the accumulating party, which in practice can be the verifier.

==== Additively Shared Insecure Trivial Variant
We start with a trivial solution to highlight the general approach, before making it secure in the next section. We depict the protocol in @alg:add_prover_insecure.

#show: style-algorithm
#algorithm-figure(
  "Additively Shared Discrete Logarithm Equality Proof (Insecure)",
  stroke: black,
  {
    import algorithmic: *
    Comment([Each server $i$:])
    Function(
      "partial_commitments",
      $k_i, B, D$,
      {
        LineComment(Assign[$r_i$][$bb(F)_q$], [Sample random share $r_i$])
        Assign[$R_(i,1)$][$r_i dot D$]
        Assign[$R_(i,2)$][$r_i dot B$]
        Assign[$C_i$][$k_i dot B$]
        Return[$r_i, C_i, R_(i,1), R_(i,2)$]
      },
    )
    LineBreak
    Comment([The accumulator with input from all $n$ servers:])
    Function(
      "create_challenge",
      $A, B, D, (C_1, R_(1,1), R_(1,2)), dots, (C_n, R_(n,1), R_(n,2))$,
      {
        Assign[$R_1$][$R_(1,1) + dots + R_(n, 1)$]
        Assign[$R_2$][$R_(1,2) + dots + R_(n, 2)$]
        Assign[$C$][$C_1 + dots + C_n$]
        Assign[$e$][$H(A,B, C,D,R_1, R_2) in bb(F)_q$]
        Return[$e$]
      },
    )
    LineBreak
    Comment([Each server $i$ on input $e$ from the client:])
    Function(
      "challenge",
      $k_i, r_i, e$,
      {
        Assign[$s_i$][$r_i + e dot k_i$]
        Return[$s_i$]
      },
    )
    LineBreak
    Comment([The accumulator with input from all $n$ servers:])
    Function(
      "combine_proofs",
      $e, s_1, ..., s_n$,
      {
        Assign[$s$][$s_1 + dots + s_n$]
        Return[$e, s$]
      },
    )
  },
)  <alg:add_prover_insecure>

@alg:add_prover_insecure requires two communication rounds between each server and the accumulator, but the servers do not need to communicate with any other server. Thereby, each random share of the server is protected by the discrete logarithm hardness assumption, preventing the accumulator from learning anything about the secrets $k, r$ and their shares.

In essence, @alg:add_prover rewrites the non-interactive prove back to its interactive version. Thus, the accumulator would not need to sample the random value $e$ via the Fiat-Shamir random oracle. However, keeping the same verifier as in the non-distributed version and keeping public verifiability (i.e., proving on chain the proof was not simulated) requires the usage of the random oracle. Since the provers do not chose the challenge via Fiat-Shamir themselves, each server should only respond at most once to a challenge for an existing random share $r_i$.

==== ROS Attacks

Since the client in @alg:add_prover_insecure can choose the challenge, the scheme unfortunately allows for forgery attacks, concretely the so-called ROS attacks @BenhamoudaLLO021. Luckily, since the discrete logarithm equality proof is essentially an extension to standard Schnorr proofs, we can use techniques proposed in the Frost line of threshold signatures (e.g., Frost1 @KomloG20, Frost2 @CritesKM21, and Frost3 @Frost3) to defend against these attacks. The main technique to fix this issue is to i) move the challenge creation to each individual server; ii) split the nonce $r$ and its commitment $R$ ($R_1$ and $R_2$ in our case) into two individual ones; iii) combine the two individual commitments back to $R$ using randomness $b$ depending on the (combined) commitments of all servers. As a result, whenever the adversary tries to change the commitment $R_2$, the randomness $b$ changes and so does the effective $R$ of an honest signer. We refer to @NickRS21, Section 2, for a more detailed discussion on why this protects against these types of attacks.

==== Additively Shared Variant Secure against ROS attacks

We now present our secure variant of the threshold discrete logarithm equality proof in @alg:add_prover following the techniques from @Frost3.

#show: style-algorithm
#algorithm-figure(
  "Additively Shared Discrete Logarithm Equality Proof",
  stroke: black,
  {
    import algorithmic: *
    Comment([Each server $i$:])
    Function(
      "partial_commitments",
      $k_i, A, G$,
      {
        LineComment(Assign[$d_i$][$bb(F)_q$], [Sample random share $d_i$])
        LineComment(Assign[$e_i$][$bb(F)_q$], [Sample random share $e_i$])
        Assign[$D_(i,1)$][$d_i dot G$]
        Assign[$D_(i,2)$][$d_i dot A$]
        Assign[$E_(i,1)$][$e_i dot G$]
        Assign[$E_(i,2)$][$e_i dot A$]
        Assign[$B_i$][$k_i dot A$]
        Return[$(d_i, e_i), B_i, D_(i,1), D_(i,2), E_(i,1), E_(i,2)$]
      },
    )
    LineBreak
    Comment([The accumulator with input from all $n$ servers:])
    Function(
      "recombine_commitments",
      $(B_1, D_(1,1), D_(1,2), E_(1,1), E_(1,2)), dots, (B_n, D_(n,1), D_(n,2), E_(n,1), E_(n,2))$,
      {
        Assign[$D_1$][$D_(1,1) + dots + D_(n, 1)$]
        Assign[$D_2$][$D_(1,2) + dots + D_(n, 2)$]
        Assign[$E_1$][$E_(1,1) + dots + E_(n, 1)$]
        Assign[$E_2$][$E_(1,2) + dots + E_(n, 2)$]
        Assign[$B$][$B_1 + dots + B_n$]
        Return[$D_1,D_2,E_1,E_2,B$]
      },
    )
    LineBreak
    Comment([Each server $i$ on input $(D_1,D_2,E_1,E_2,B)$ from the client:])
    Function(
      "challenge",
      $k_i, d_i, e_i, K, A, B, G, D_1, D_2, E_1, E_2$,
      {
        LineComment(
          Assign[$b$][$H_b (T, K, B, D_1, D_2, E_1, E_2) in bb(F)_q$],
          [$T$ is the ordered set of participating parties.],
        )
        Assign[$R_1$][$D_1+ b dot E_1$]
        Assign[$R_2$][$D_2+ b dot E_2$]
        Assign[$e$][$H(K, A, B, G, R_1, R_2) in bb(F)_q$]
        Assign[$s_i$][$d_i + b dot e_i + e dot k_i$]
        Return[$s_i$]
      },
    )
    LineBreak
    Comment([The accumulator with input from all $n$ servers:])
    Function(
      "combine_proofs",
      $s_1, ..., s_n, K, A, B, G, D_1, D_2, E_1, E_2$,
      {
        Assign[$b$][$H_b (T, K, B, D_1, D_2, E_1, E_2) in bb(F)_q$]
        Assign[$R_1$][$D_1+ b dot E_1$]
        Assign[$R_2$][$D_2+ b dot E_2$]
        Assign[$e$][$H(K, A, B, G, R_1, R_2) in bb(F)_q$]
        Assign[$s$][$s_1 + dots + s_n$]
        Return[$e, s$]
      },
    )
  },
)  <alg:add_prover>

The main differences to @alg:add_prover_insecure are that i) each server responds to the first request by the client with 5 commitments instead of 3; ii) the client sends 5 commitments instead of the challenge to the server in the second round; iii) and the client computes the challenge itself in the end.

=== Shamir Shared Discrete Logarithm Equality Proof

In order to rewrite @alg:add_prover from additive to Shamir secret-sharing, we have to make the following changes. First, the share $k_i$ needs to be a valid Shamir share. Second, reconstructions of elements involving $k_i$ (i.e., $C$ from all $C_i$, and $s$ from $s_i$) require lagrange interpolation. The latter requires the client to chose $d+1$ servers (where $d$ is the chosen degree of the underlying sharing polynomial) as a signing set $T$. We further include $T$ in the random oracle choosing $b$ as well. We depict the final protocol in @alg:shamir_prover, highlighting the changes to @alg:add_prover in blue.

#show: style-algorithm
#algorithm-figure(
  "Shamir Shared Discrete Logarithm Equality Proof",
  stroke: black,
  {
    import algorithmic: *
    Comment([Each server $i$:])
    Function(
      "partial_commitments",
      $k_i, A, G$,
      {
        LineComment(Assign[$d_i$][$bb(F)_q$], [Sample random share $d_i$])
        LineComment(Assign[$e_i$][$bb(F)_q$], [Sample random share $e_i$])
        Assign[$F_(i,1)$][$d_i dot G$]
        Assign[$F_(i,2)$][$d_i dot A$]
        Assign[$G_(i,1)$][$e_i dot G$]
        Assign[$G_(i,2)$][$e_i dot A$]
        Assign[$B_i$][$k_i dot A$]
        Return[$d_i, e_i, B_i, D_(i,1), D_(i,2), E_(i,1), E_(i,2)$]
      },
    )
    LineBreak
    Comment([The accumulator with input from $t = d+1$ out of $n$ servers:])
    Function(
      "recombine_commitments",
      $(B_1, D_(1,1), D_(1,2), E_(1,1), E_(1,2)), dots, (B_t, D_(t,1), D_(t,2), E_(t,1), E_(t,2))$,
      {
        Assign[$D_1$][$D_(1,1) + dots + D_(t, 1)$]
        Assign[$D_2$][$D_(1,2) + dots + D_(t, 2)$]
        Assign[$E_1$][$E_(1,1) + dots + E_(t, 1)$]
        Assign[$E_2$][$E_(1,2) + dots + E_(t, 2)$]
        Assign[$B$][$#emph(text(blue)[$lambda_1$])dot B_1 + dots + #emph(text(blue)[$lambda_t$])dot B_t$]
        Return[$D_1,D_2,E_1,E_2,B$]
      },
    )
    LineBreak
    Comment(
      [Each server $i$ on input  $(D_1,D_2,E_1,E_2,B)$ and the signing set #emph(text(blue)[$T$]) from the client:],
    )
    Function(
      "challenge",
      $k_i, d_i, e_i, K, A, B, G, D_1, D_2, E_1, E_2, #emph(text(blue)[$T$]))$,
      {
        Assign[$b$][$H_b (#emph(text(blue)[$T$]), K, B, D_1, D_2, E_1, E_2) in bb(F)_q$]
        Assign[$R_1$][$D_1+ b dot E_1$]
        Assign[$R_2$][$D_2+ b dot E_2$]
        Assign[$e$][$H(K, A, B, G,R_1, R_2) in bb(F)_q$]
        Assign[$s_i$][$d_i + b dot e_i + e dot k_i dot #emph(text(blue)[$lambda_i$])$]
        Return[$s_i$]
      },
    )
    LineBreak
    Comment([The accumulator with input from $t = d+1$ out of $n$ servers:])
    Function(
      "combine_proofs",
      $s_1, ..., s_t, K, A, B, G, D_1, D_2, E_1, E_2$,
      {
        Assign[$b$][$H_b ( #emph(text(blue)[$T$]), K, B, D_1, D_2, E_1, E_2) in bb(F)_q$]
        Assign[$R_1$][$D_1+ b dot E_1$]
        Assign[$R_2$][$D_2+ b dot E_2$]
        Assign[$e$][$H(K, A, B, G, R_1, R_2) in bb(F)_q$]
        Assign[$s$][$s_1 + dots + s_t$]
        Return[$e, s$]
      },
    )
  },
)  <alg:shamir_prover>

In order to chose the signing set $T$ we propose that the client sends the first request to all $n$ servers, and chooses the fastest $d+1$ responding servers for engaging in the second round to complete the protocol, keeping the identifiers in T canonically ordered.

=== On Communication Patters

#todo("Client as Aggregator vs one of the Servers", position: "inline")

== Full Distributed, OPRF Protocol with Public Verifiability

In this section, we present the full threshold OPRF protocol with additions to make the clients execution of the OPRF publicly verifiable. The final statement the client proves is the following:
"I know an input $x$, that is committed to as $com$, and the output of the OPRF using the public key $K$ is $y$."

#figure(
  rect(table(
    columns: (2fr, 1fr, 2fr),
    stroke: none,
    table.header([Client($x, K, G$)], [], [$n$ Servers($k_i, K = k dot G$)]),
    table.hline(stroke: 0.05em),
    [$beta arrowrl bb(Z)_q^*$], [], [],
    [$r arrowrl bb(Z)_p$], [], [],
    [$com <- H_"com" (x, r)$], [], [],
    [$A <- beta dot H_1(x)$], [], [],
    [],
    math.attach($arrow.r$, t: $A$),
    [], [], [],
    [$((d_i, e_i), B_i, D_(i,1), D_(i,2), E_(i,1), E_(i,2)) <- #linebreak() mono("dlog.partial_commitments")(k_i, A, G)$],
    [$T$ is the set of $t$ used parties], math.attach($arrow.l$, t: $[B], [D_1], [D_2], [E_1], [E_2]$), [],
    [$(B, D_1, D_2, E_1, E_2) <-#linebreak() mono("dlog.recombine_commitments")( [B], #linebreak() [D_1], [D_2], [E_1], [E_2])$],
    [],
    [],
    [], math.attach($arrow.r$, t: $B, D_1, D_2, E_1, E_2, T$), [],
    [], [], [$s_i <-mono("dlog.challenge")(k_i, d_i, e_i, #linebreak() K, A, B, G, D_1, D_2, E_1, E_2, T)$],
    [$(e,s) <-mono("dlog.combine_proofs")(#linebreak()s_1, ..., s_t, K, A, B, G, D_1, D_2, E_1, E_2)$],
    math.attach($arrow.l$, t: $[s]$),
    [],
    [$y <- H_2(x, (beta^(-1) dot B))$], [], [],
    [$pi_"oprf" <-mono("prove_oprf")((y, com, K), #linebreak() (x, beta, e, s, B))$], [], [],
    [Output $(y, com, pi_"oprf")$],
  )),
  caption: [The verifiable threshold TwoHashDH OPRF construction derived from @fig:twohashdh.],
  kind: "scheme",
  supplement: [Scheme],
)
<fig:full_protocol>


=== Client Side ZK Proof

The client, after executing the OPRF with the set of servers proves that the OPRF output $y$ is well-formed with respect to the input commitment $com$ and the OPRF public key $K$. This is achieved by proving the validity of a rank 1 constraint system (R1CS) that maps to @alg:prove_oprf.

#show: style-algorithm
#algorithm-figure(
  [Client Side OPRF proof $pi_"oprf"$],
  stroke: black,
  {
    import algorithmic: *

    Comment(
      [With public inputs $(y, com, K)$ and private inputs $(x, beta, r, e, s, B)$],
    )
    Function(
      "prove_oprf",
      $(y, com, K), (x, beta, r, e, s, B)$,
      {
        Assign($com'$, $H_"com" (x, r)$)
        Line($mono("assert") com' == com$)
        Assign($Q$, $H_1(x)$)
        Assign($A$, $Q dot beta$)
        Line($mono("assert") mono("DLogEQ.Verify")(K,B,G,A,e,s)$)
        Assign($Q_2$, $B dot beta^-1$)
        Assign($y'$, $H_2 (x, Q_2)$)
        Line($mono("assert") y' == y$)
      },
    )
    LineBreak
  },
)
<alg:prove_oprf>

#linebreak()
We will now go through @alg:prove_oprf line by line and explore the relative costs for performing these operations in a zkSNARK.
- Line 3: Recomputing the input commitment hash, instantiated using Poseidon2, about 240 R1CS constraints.
- Line 5: Recomputing the `encode_to_curve` function, about 800 R1CS constraints.
- Line 6: Recomputing the scalar multiplication with the blinding factor, about 2300 R1CS constraints.
- Line 7: Verifying that the DLogEQ proof is correct, about 12000 R1CS constraints.
- Line 8: Recomputing the scaler multiplication with the blinding factor, about 2300 R1CS constraints.
- Line 9: Recomputing the OPRF output hash, instantiated using Poseidon2, about 260 R1CS constraints.

#remark[On ZK optimizations and additional checks][We utilize various common optimizations in the above ZK circuit. For example, instead of having to compute the inverse of $beta$ in line 8, we inject $Q_2$ as an additional input and verify that $B = Q_2 dot beta$. However, additional care needs to be taken for such steps, as the co-factor of BabyJubJub is not 1. Therefore, we additionally need to check that $Q_2$ is a point in the prime-order subgroup of BabyJubJub, otherwise there might be combinations of $Q_2$ and $beta$ where multiple points $Q_2$ map to the same $B$, making the ZK proof malleable. ]


= Use Case: OPRF-Based Nullifier Protocol

We give the full verifiable OPRF based distributed nullifier service construction in @fig:full_protocol. For the description of the zero-knowledge proofs $pi_1$ and $pi_2$ we refer to @sec:ZK.

#figure(
  rect(table(
    columns: (2fr, 1fr, 2fr),
    stroke: none,
    table.header([Client($sk, pk, uid, rpid, action, K$)], [], [$n$ Server($k_i, K = k dot B$)]),
    table.hline(stroke: 0.05em),
    [$beta arrowrl bb(Z)_q^*$], [], [],
    [$q <- H_1(uid, rpid, action)$], [], [],
    [$sigma <-mono("Sign")(sk, q)$], [], [],
    [$A <- beta dot H_2(q)$], [], [],
    [$pi_1 <-mono("prove")(sigma, A,mono("valid")(pk))$],
    math.attach($arrow.r$, t: $A, pi_1, action, rpid$),
    [if $mono("verify")(pi_1, A, action, rpid) = bot$ then abort],
    [],
    [],
    [$(f_i, g_i, C_i, F_(i,1), F_(i,2), G_(i,1), G_(i,2)) <- #linebreak() mono("dlog.partial_commitments")(k_i, A, B)$],
    [$C <-mono("Shamir.Reconstruct")([C])$], math.attach($arrow.l$, t: $[C], [F_1], [F_2], [G_1], [G_2]$), [],
    [$F_1 <-mono("Reconstruct")([F_1])$], [], [],
    [$F_2 <-mono("Reconstruct")([F_2])$], [], [],
    [$G_1 <-mono("Reconstruct")([G_1])$], [], [],
    [$G_2 <-mono("Reconstruct")([G_2])$], math.attach($arrow.r$, t: $C, F_1, F_2, G_1, G_2, T$), [],
    [], [], [$s_i <-mono("dlog.challenge")(k_i, f_i, g_i, #linebreak() A, B, C, D, F_1, F_2, G_1, G_2,T)$],
    [$(e,s) <-mono("dlog.combine_proofs")(#linebreak()s_1, ..., s_t, A, B, C, D, F_1, G_1, F_2, G_2)$],
    math.attach($arrow.l$, t: $[s]$),
    [],
    [$n <- H_4(q, (beta^(-1) dot C))$], [], [],
    [$pi_2 <-mono("prove")(sigma, A, #linebreak() mono("valid")(pk), mono("dlog.verify")(e,s), n)$], [], [],
    [Output $(n, pi_2)$],
  )),
  caption: [The verifiable threshold TwoHashDH based nullifier construction derived from @fig:twohashdh.],
  kind: "scheme",
  supplement: [Scheme],
)
<fig:full_protocol_use_case>

=== Clients Zero-Knowledge Proofs <sec:ZK>

We describe the ZK proofs $pi_1$ and $pi_2$ from @fig:full_protocol_use_case in this section.

==== Query Proof $pi_1$

The goal of the query proof $pi_1$ is to convince the server that a client is authorized to send a request. Therefore, $mono("valid")(pk)$ is a core part of this zero-knowledge proof which shows that the used public key $pk$ is in some kind of allowlist. To prove knowledge of the corresponding private key $sk$ we opt to verify a signature $sigma <-mono("Sign")(sk, q)$ of the actual query $q$ inside the ZK proof to not have $sk$ as a private witness in the proof. This has the advantage that a client can securely outsource proof generation to, e.g., an MPC-based prover network, without having to secret-share its key $sk$ with them, minimizing damage in case of a privacy breach.

Finally, $pi_1$ binds everything together by proving the correct calculation of the query point $A$ from its parts.

In more details, proof $pi_1$ consists of the following statements:
#figure(
  box(stroke: black, inset: 1em)[
    #align(left)[
      *Proof $pi_1 <-mono("prove")(sigma, A,mono("valid")(pk))$:*
      1. The query $q$ is computed as the hash $q <- H_1(uid, rpid, action)$ where we use Poseidon2 for $H_1$ due to its ZK friendliness.
      2. The signature $sigma$ is a valid EdDSA signature of $q$ using some key $sk$. This is done by proving the EdDSA verifier inside the ZK proof, such that $sk$ is not part of the witness.
      3. The public key $pk$ used to verify the signature $sigma$ is part of an allowlist. Concretely, this allowlist is currently implemented as a Merkle tree accumulator with the root node $m$ and a list of $t$ public keys at each leaf. Proving this statement is done by showing:
        - The hash of the $t$ public keys is the actual leaf $pk'$ of a Merkle tree
        - The prover knows a path from $pk'$ to the root node $m$. This path consists of the sibling nodes in each level of the tree, as well as the position of the leaf which is $uid$.
        - $pk$ used for verifying the signature is at some index $i$ (known to the prover) in the list of all $t$ public keys.
      4. Finally, the derivation of the query point $A$ is computed correctly by proving $A<-beta dot H_2(q)$ where $H_2(q)$ hashes $q$ onto the BabyJubJub curve and $beta$ is a blinding element.
    ]],
  caption: [The statements proven in $pi_1$.],
)<fig:pi1>

The following elements need to be public inputs to $pi_1$:
- $rpid$ needs to be a public input, such that the OPRF servers know which secret $k$ (which belongs to the specified RP) they need to use in their response.
- $action$ is currently a public field element to bind the nullifier to a specific action publicly. If this is undesired, $action$ can also be made private with no downside since $action$ is part of the nullifier computation and can thus not be requested a second time.
- The Merkle root $m$ is a public input to bind the validity check of $pk$ to a known allowlist.
- The query point $A$ is public such that the OPRF servers can verify the requests by the client.

==== Nullifier Proof $pi_2$

The role of $pi_2$ is having a proof of the full nullifier construction. Thus, it needs to prove the following statements:
#figure(
  box(stroke: black, inset: 1em)[
    #align(left)[
      *Proof $pi_2 <-mono("prove")(sigma, A,mono("valid")(pk), mono("dlog.verify")(e,s), n)$:*
      1. All 4 statements of the query proof $pi_1$ from @fig:pi1 are proven.
      2. The discrete logarithm equality proof from the OPRF servers is verified to show that the servers computed the response honestly. This is done by evaluating the verifier from @alg:prover inside the ZK proof, similar to proving the correct EdDSA signature.
      3. The OPRF result is unblinded and hashed to get the OPRF output $n = H_4(q, beta^(-1)dot C)$. To avoid inverting $beta$ in the BabyJubJub scalarfield $bb(F)_q$ inside a ZK proof over a different prime field $bb(F)_p$ (the BabyJubJub basefield) we prove the unblinding step via injecting the result $C'= beta^(-1)dot C$, showing it is a valid BabyJubJub point and proving $C=beta dot C'$.
      4. We allow a message $serif("msg") in bb(F)_p$ to be part of the proof. To disallow tampering of the proof, we add a constraint squaring the message (as is also done in a standard Semaphore proof).
    ]],
  caption: [The statements proven in $pi_2$.],
)<fig:pi2>


The following elements need to be public inputs to $pi_2$:
- $rpid$ needs to be a public input, such that everyone can verify that the nullifier was computed for a specific RP.
- $action$ is currently a public field element to bind the nullifier to a specific action publicly. If this is undesired, $action$ can also be made private with no downside since $action$ is part of the nullifier computation and can thus not be requested a second time.
- The OPRF public key $K = k dot B$ to show that the correct key $k$ was used in the OPRF evaluation.
- The Merkle root $m$ is a public input to bind the validity check of $pk$ to a known allowlist.
- The message $serif("msg")$ which is also part of the proof.
- The final nullifier $n$ is public to bind the nullifier to the proof.

=== Key Generation and Reshare

In this section, we discuss how to generate the Shamir-shared OPRF key $k$ and how it can be reshared with a potentially new set of key holders. This reshare protocol can also be used to refresh the existing shares by resharing to the same set of computing nodes. We begin by describing the maliciously secure distributed key generation with identifiable abort from @CritesKM21 (which is dubbed PedPoP) which allows to securely generate a fresh Shamir secret with any threshold of corrupted parties $t < n$. We refer to @sec:keygen for two proposals on how to translate this to a practical on-chain implementation.

=== Pedersen's Protocol with Proof of Possession (PedPoP) @CritesKM21
The PedPoP protocol is an adaption of the protocol introduced in @KomloG20. It is basically a parallel instantiation of verifiable secret-sharing (VSS) based on Shamir secret-sharing with the addition of vector commitments and Schnorr proofs to ensure that communicated shares are consistent and that unforgeability holds even if more than half of the parties are corrupted. Furthermore, the protocol allows to detect and disqualify malicious parties during the key generation protocol. We depict the protocol in @scheme:pedpop.

#figure(
  box(stroke: black, inset: 1em)[
    #align(left)[
      - *Round1*:
        1. Each party $P_i$ chooses a random polynomial $f_i (Z)$ over $bb(F)_p$ of degree $t$ $ f_i (Z) = a_(i,0) + a_(i,1) Z + dots + a_(i,t) Z^t $ and computes $A_(i,k) = G^(a_(i,k))$ for $k in[t]$. Denote $x_i= a_(i,0)$ and $X_i = A_(i,0)$. Each $P_i$ computes a proof of possession of $X_i$ as a Schnorr signature as follows. They sample $r_i arrowrl bb(F)_p$ and set $R_i arrow.l G^(r_i)$. They set $c_i arrow.l H(R_i, X_i)$ and set $z_i arrow.l r_i + c_i dot x_i$. They then derive a commitment $arrow(C)_i = (A_(i,0), dots, A_(i, t-1))$ and broadcast $((R_i, z_i), arrow(C)_i)$.
        2. After receiving the commitment from all other parties, each participant verifies the Schnorr signature by computing $c'_j arrow.l H(R_j, A_(j, 0))$ and checking that $ R_j A_(j,0)^(c'_j) = G^(z_j). $ If any checks fail, they disqualify the corresponding participant; otherwise, they continue to the next step.
      - *Round2*:
        3. Each $P_i$ computes secret-shares $x_(i,j) = f_i (serif(id)_j)$ for $j = 1, dots, n$, where $serif(id)_j$ is the participant identifier, and sends $x_(i,j)$ secretly to party $P_j$.
        4. Each party $P_j$ verifies the shares they received from the other parties by checking that $ G^(x_(i,j)) = product_(k=0)^(t)A_(i,k)^(serif(id)_j^k) $ If the check fails for an index $i$, then $P_j$ broadcasts a complaint against $P_i$.
      - *Round3*:
        5. For each of the complaining parties $P_j$ against $P_i$, $P_i$ broadcasts the share $x_(i,j)$. If any of the revealed shares fails to satisfy the equation, or should $P_i$ not broadcast anything for a complaining player, then $P_i$ is disqualified. The share of a disqualified party $P_i$ is set to $0$.
      - *Output*:
        6. The secret-share for each $P_j$ is $s_j = sum_(i=1)^n x_(i,j)$.
        7. If $X_i=X_j$ for any $i != j$, then abort. Else, the output is the joint public key $serif(pk)=product_(i=1)^n X_i$.
    ]],
  caption: [The PedPoP key generation protocol @CritesKM21.],
)<scheme:pedpop>

=== PedPoP Reshare Protocol

After the pair $[serif(sk)], serif(pk)$ is generated, one can use a combined version of the reshare algorithm from @ChoudhuriGGJK21 and the PedPoP protocol @CritesKM21 to reshare the key $[serif(sk)]$ to a new set of parties, while also maintaining its correctness, privacy, and the possibility to identify malicious parties. While the original PedPoP key generation protocol requires 3 communication rounds (2 rounds for the computation plus an extra round for blaming malicious parties), our PedPoP reshare protocol only requires 2 rounds. During key generation, performing the two computation rounds in parallel would allow malicious parties to potentially introduce a bias into the random key. Since during resharing the key is already fixed, one does not need to protect against this attack vector and can perform the two communication rounds in parallel. We depict our resharing protocol in @scheme:pedpop_reshare.

#figure(
  box(stroke: black, inset: 1em)[
    #align(left)[
      - *Round1*:
        1. To reshare the share $x_i$ each party $P_i$ chooses a random polynomial $f_i (Z)$ over $bb(F)_p$ $ f_i (Z) = x_i + a_(i,1) Z + dots + a_(i,t) Z^t $ and computes $A_(i, k) = G^(a_(i, k))$ for $k in[t]$. Denote $X_i = A_(i, 0) = G^(x_i)$. Each $P_i$ computes a proof of possession of $X_i$ as a Schnorr signature as follows. They sample $r_i arrowrl bb(F)_p$ and set $R_i arrow.l G^(r_i)$. They set $c_i arrow.l H(R_i, X_i)$ and set $z_i arrow.l r_i + c_i dot x_i$. They then derive a commitment $arrow(C)_i = (A_(i, 0), dots, A_(i, t-1))$ and broadcast $((R_i, z_i), arrow(C)_i)$ to the new set of parties.
        2. After receiving the commitment from all old parties, each participant of the new set of parties verifies the Schnorr signature by computing $c'_j arrow.l H(R_j, A_(j, 0))$ and checking that $ R_j A_(j,0)^(c'_j) = G^(z_j). $ Verify, that $A_(j,0)$ is equal to the commitment one receives by interpolating the commitments from Step 4 from the previous reshare round (in the exponent). If any checks fail, they accuse the corresponding participant and remove its contribution; otherwise, they continue to the next step.
      - *Round2* (In parallel to Round 1):
        3. Each $P_i$ of the old set of parties computes secret-shares $x_(i,j) = f_i (serif(id)_j)$ for $j = 1, dots, n$, where $serif(id)_j$ is the participant identifier, and sends $x_(i,j)$ secretly to party $P_j$ of the new set.
        4. Each party $P_j$ of the new set verifies the shares they received from the old parties:
          $ G^(x_(i,j)) = product_(k=0)^(t)A_(i,k)^(serif(id)_j^k) $
          If the check fails for an index $i$, then $P_j$ broadcasts a complaint against $P_i$ from the old set.
      - *Round3*:
        5. For each of the complaining parties $P_j$ against $P_i$, $P_i$ broadcasts the share $x_(i,j)$. If any of the revealed shares fails to satisfy the equation, or should $P_i$ not broadcast anything for a complaining player, then $P_i$ is disqualified. The share of a disqualified party $P_i$ is ignored.
      - *Output*:
        6. The secret-share for each $P_j$ is $s_j = sum_(i=1)^n x_(i,j)lambda_i$, where $lambda_i$ is the corresponding lagrange coefficient.
        7. Check, whether the output $product_(i=1)^n X_i^(lambda_i)$ is equal to the public key $serif(pk)$. This should always happen if there are at most $t$ cheating parties.
    ]],
  caption: [The PedPoP reshare protocol.],
)<scheme:pedpop_reshare>

= Evaluation

In this section we report some preliminary performance numbers of our proposed protocols.

== ZK Proofs: Circom

We implemented the zero-knowledge proofs $pi_1$ and $pi_2$ from @sec:ZK in Circom and report on the number of R1CS constraints of parts and the full proofs in this Section. The numbers are reported in @tab:circom_constraints for a Merkle tree registry of depth $d=32$ which allows to hold $t=7$ public keys in its leaves.

#figure(
  table(
    columns: 3,
    align: (left, right, left),
    stroke: none,
    table.header([Function], [Constraint Cost], [Comment]),
    table.hline(stroke: 0.05em),
    [BabyJubJubScalarMulAny], [2310], [$s dot P$ for arbitrary $P$, 254 bit $s$.],
    [BabyJubJubScalarMulFix], [512], [$s dot P$, for fixed, public $P$, 254 bit $s$.],
    [Poseidon2 (t=2)], [216], [Poseidon2 with statesize 2.],
    [Poseidon2 (t=3)], [240], [Poseidon2 with statesize 3.],
    [Poseidon2 (t=4)], [265], [Poseidon2 with statesize 4.],
    [Poseidon2 (t=8)], [363], [Poseidon2 with statesize 8.],
    [Poseidon2 (t=16)], [555], [Poseidon2 with statesize 16.],
    [EdDSAPoseidon2Verifier], [5615], [EdDSA Verification on BabyJubJub, using Poseidon2 as a Hash.],
    [EncodeToCurveBabyJubJub], [808], [Encoding an arbitrary field element into a random BabyJubJub Curve point.],
    [DLogEqVerify], [12287], [Verification of a discrete logarithm equality proof over BabyJubJub.],
    [BinaryMerkleTree (d=32)], [7875], [Binary Merkle Tree using Poseidon2 with state size 2, depth 32.],
    [Semaphore (d=32)], [9383], [Semaphore proof with MT depth 32.],
    table.hline(stroke: 0.05em),
    [OprfQuery (d=32)], [17325], [Full OPRF query proof $pi_1$],
    [OprfNullifier (d=32)], [32414], [Full OPRF nullifier proof $pi_2$],
  ),
  caption: [Constraint cost for various Circom ZK building blocks.],
) <tab:circom_constraints>


#bibliography("references.bib")


#appendices(
  [
    = Random sampling

    Let $p$ be the order of the BN254 curve and $q$ be the order of the BabyJubJub curve (see @sec:babyjubjub).

    #theorem(
      [Given a uniform random element $x in bb(F)_p$, the distributions $x mod q$ and $x arrowrl bb(F)_q$ are statistically indistinguishable.],
    )
    #v(-1cm)
    #proof(
      [Let $r = 8q$, then $r approx p + 2^(125.637)$. The distributions $x arrowrl bb(Z)_p$ and $y arrowrl bb(Z)_r$ are distinguishable only if the drawn element is from the gap of the two ranges, i.e. from the interval \[p, r\). This event happens with probability $(r-p)/r approx 2^(125.637)/r approx 1/2^(127.96)$, which is negligible, meaning our two distributions are statistically indistinguishable. For the second part of the proof, observe that $r$ is an exact multiple of $q$ by design. This means that the distributions $x arrowrl bb(Z)_q; "return" x$ and $y arrowrl bb(Z)_r; "return" y mod q$ are indistinguishable, since $bb(Z)_q$ is a subgroup of $bb(Z)_r.$ Putting the two facts together concludes the proof.],
    )

    = Shamir Key Generation and Resharing Proposals <sec:keygen>

    In this section we propose two protocols on how to instantiate the Shamir secret-sharing based key generation and reshare procedures.

    == Proposal 1

    Based on @scheme:pedpop we design a blockchain-assisted key generation protocol that does not require the parties to have direct communication channels with each other. However, knowledge of their respective public keys is required. We depict this protocol in @scheme:proposal1.

    #figure(
      box(stroke: black, inset: 1em)[
        #align(left)[
          - *Round1*:
            1. Each party $P_i$ chooses a random polynomial $f_i (Z)$ over $bb(F)_p$ of degree $t$ $ f_i (Z) = a_(i,0) + a_(i,1) Z + dots + a_(i,t) Z^t $ and computes $A_(i,k) = G^(a_(i,k))$ for $k in[t]$. Denote $x_i= a_(i,0)$ and $X_i = A_(i,0)$. Each $P_i$ computes a proof of possession of $X_i$ as a Schnorr signature as follows. They sample $r_i arrowrl bb(F)_p$ and set $R_i arrow.l G^(r_i)$. They set $c_i arrow.l H(R_i, X_i)$ and set $z_i arrow.l r_i + c_i dot x_i$. They then derive a commitment $arrow(C)_i = (A_(i,0), dots, A_(i, t-1))$ and post $((R_i, z_i), arrow(C)_i)$ on chain.
            2. The smart contract verifies the Schnorr signature by computing $c'_j arrow.l H(R_j, A_(j, 0))$ and checking that $ R_j A_(j,0)^(c'_j) = G^(z_j). $ If no error was found, the smart contract stores the commitments $arrow(C)$.
          - *Round2*:
            3. Each $P_i$ computes secret-shares $x_(i,j) = f_i (serif(id)_j)$ for $j = 1, dots, n$, where $serif(id)_j$ is the participant identifier, and posts an encryption of $x_(i,j)$ using $P_j$'s public key on chain.
            4. Each party $P_j$ reads the shares from the other parties from the chain and check that $ G^(x_(i,j)) = product_(k=0)^(t)A_(i,k)^(serif(id)_j^k). $  If the check fails for an index $i$, then $P_j$ posts a complaint against $P_i$ on chain.
          - *Round3*:
            5. Each party has a predefined amount of time to post complaints on chain. For each of the complaining parties $P_j$ against $P_i$, $P_i$ broadcasts the share $x_(i,j)$. If any of the revealed shares fails to satisfy the equation, or should $P_i$ not broadcast anything for a complaining player, then $P_i$ is slashed and the protocol aborts.
          - *Output*:
            6. The secret-share for each $P_j$ is $s_j = sum_(i=1)^n x_(i,j)$.
            7. The smart contract checks if $X_i=X_j$ for any $i != j$ in which case it aborts. Otherwise, it computes the public key from the commitments $serif(pk)=product_(i=1)^n X_i$.
        ]],
      caption: [Proposal 1 for key generation based on PedPoP @CritesKM21.],
    )<scheme:proposal1>

    @scheme:proposal1 has the following (undesired) property: If party $P_j$ files a complaint against $P_i$ (round 3) the share $x_(i,j)$ is leaked. To prevent this, one can build the complaint round differently. If $P_j$ makes a complaint against $P_i$, then $P_i$ has to post a ZK proof that the share was derived correctly (using the commitments to the polynomials on chain) and that the encryption of the share on chain matches the correctly derived share. If that is the case, $P_j$ filed a wrong complaint and is slashed. Otherwise, or if $P_i$ fails to provide a proof in time, $P_i$ is slashed.

    The cost of the ZK proof is $t + 1$ BabyJubJubScalarMulFix for checking the commitments, one  BabyJubJubScalarMulFix plus one BabyJubJubScalarMulAny for deriving a secret key for encryption using Diffie-Hellman key agreement with the public keys of $P_i$ and $P_j$, a Poseidon2 based encryption, and a recomputation of the polynomial evaluation over $bb(F)_q$ for deriving the correct share. Since the polynomial evaluation is over a field which is not native to the ZK proof, this evaluation is estimated to be the most costly part of the proof. Implementing an additionModQ gadget requires an estimate of 500 constraints, whereas multiplication mod $q$ can be implemented as a double-and-add ladder since the multiplications are with small constants (the evaluation point is the party id $j$) when using Horner's polynomial evaluation technique. Furthermore, this evaluation scales linearly with the degree of the polynomial $t$.

    To allow this complaint proof to be generic for thresholds which might change later on, the circuit can be modified to an upper bound of $t'$, and have the concrete $t$ as a public input. This requires to Cmux each random coefficient with 0 in case its index is greater $t$ and recomputing $t'$ commitments using BabyJubJubScalarMulFix. Furthermore, it could make sense to accumulate the commitments using Poseidon2 to reduce the number of public inputs.

    For reshare, we modify @scheme:pedpop_reshare similar as for @scheme:proposal1, with the additional constraint that the commitments to the new shares have to produce the same public key. This should come implicitly since the smart contract has to check that the correct share was used by interpolating the commitments in the exponent anyways (step 2 in @scheme:pedpop_reshare).

    Finally, for both the key generation and reshare, the proof of possession (i.e., the Schnorr proof in Step 1) is not strictly required and can be skipped.

    To summarize, Proposal 1 has the advantage that it is very simple and easy to compute and does not require a direct network channel between the computing parties. Furthermore, it is publicly verifiable that the parties keep the same secret during a reshare procedure. However, the public can not verify that all parties behaved correctly without one of the parties posting a complaint on chain.

    == Proposal 2

    The second proposal aims to achieve full verifiability with ZK proofs on chain. While the ZK proofs are more expensive compared to Proposal 1, they get rid of the complaint round and smart contracts only accept values if a ZK proof of correctness was provided. We depict the protocol in @scheme:proposal2.

    #figure(
      box(stroke: black, inset: 1em)[
        #align(left)[
          - *Round1*:
            1. Each party $P_i$ chooses a random polynomial $f_i (Z)$ over $bb(F)_p$ of degree $t$ $ f_i (Z) = a_(i,0) + a_(i,1) Z + dots + a_(i,t) Z^t, $ computes $X_i = G^(a_(i,0))$ and $c = H(a_(i,1), dots, a_(i, t))$, and posts $X_i$ and $c$ on chain.
          - *Round2*:
            2. Each $P_i$ computes secret-shares $x_(i,j) = f_i (serif(id)_j)$ for $j = 1, dots, n$, where $serif(id)_j$ is the participant identifier, and posts a commitment $X_(i,j) = G^(x_(i,j))$ and an encryption of $x_(i,j)$ using $P_j$'s public key on chain, alongside a ZK proof verifying correctness.
            3. The smart contract verifies the ZK proof and accepts the encryptions of the shares if the proof is correct.
            4. Each party $P_j$ reads the shares from the other parties from the chain.
          - *Output*:
            6. The secret-share for each $P_j$ is $s_j = sum_(i=1)^n x_(i,j)$.
            7. The smart contract checks if $X_i=X_j$ for any $i != j$ in which case it aborts. Otherwise, it computes the public key from the commitments $serif(pk)=product_(i=1)^n X_i$.
        ]],
      caption: [Proposal 2 for key generation using ZK proofs.],
    )<scheme:proposal2>

    For reshare, we also have to proof that the correct share was used using the commitments $X_(i,j)$ from the previous round. However, since these commitments are public anyway, this check can be done outside of the ZK proof, e.g., in the smart contract. When computing everything into one ZK proof (per party), the proof consists of the following:
    - Deriving the $n$ shares:
      - Requires $n$ polynomial evaluations in a non-native field
    - Recomputing the commitments:
      - Poseidon2 commitment for $t$ inputs.
      - A BabyJubJubScalarMulFix for the commitment $X_i$.
      - $n$ BabyJubJubScalarMulFix for the commitments $X_(i,j)$.
    - For the Encryption:
      - $1$ BabyJubJubScalarMulFix for showing the secret key used for the diffie hellman matches the parties public key.
      - $n$ BabyJubJubScalarMulAny for deriving the secret keys.
      - $n$ Poseidon2 hashes for the encryption.

    Similar to the description for  @scheme:proposal1, the cost of the ZK proof is dominated by the $n$ polynomial evaluations in the non-native field $bb(F)_q$. Furthermore, constraint size scales linearly in both the degree $t$ and the number of parties $n$, making the proof very costly for larger number of parties. A first estimate for an untested implementation gives around 1 million R1CS constraints for $n=30$ and $t=15$.


    Alternatively, one can think of producing $n$ proofs for the $n$ derived shares instead of proving everything in one large proof, which comes at the disadvantage of having to pay the on-chain gas fee $n$ times.
  ],
)
